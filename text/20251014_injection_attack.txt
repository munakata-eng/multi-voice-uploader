はい どうも こんにちは 室畑です この チャンネルでは 今流行りのAI を使って 開発未経験からでもプログラミング を学ぼうというコンセプトで 開発 の基礎知識や最新のAIツールについて お話ししていきます 今日は AIや 開発のときに 何かツールとかサイト を開発してくるときに出てくる セキュリティ周りのお話で インジェクション 攻撃というものについて紹介をして いきます インジェクションって 普通に英語で言うと注射とか 注入 とか そういう意味になるんですけ れども このプログラムとか 開発 の用語で言うと どちらかと言えば 悪意のあるものが注入される 悪い ものが勝手に入れられるみたいな そういう意味合いで使われて 主に 脆弱性をついた攻撃みたいな そういう ときに使われる用語になります まず一番最初にあったので言う と ちょっと用語は覚えなくていいん ですけれども SQLインジェクション というものが結構有名で これは データベースに何かデータを保存 しますよっていう命令を送るときに データを更新する命令とか削除 する命令に デリートなんじゃら とか アップデートなんじゃらみたいな メッセージがあるんですけれども そこを 例えば テキストに名前 説明文 名前と自分の自己紹介 みたいなのを入力して データベース に保存しますよみたいな入力フォーム があったときに 例えば その説明文 のところにデリートオールみたいな すべてを削除しますよみたいな 命令を書いて その命令がそのまま サーバーのほうに送られて 何も 考えられずに実行されると データ が全部消えちゃうみたいな そんな シンプルすぎるミスは多分ない んですけれども ざっくりそういう ユーザーが自由に入力できる ところで そういったプログラム をあえて書くということをすると その先のサーバーとかに何かしら 攻撃を加えたりとか あとはデータ を抜き取るみたいな そういうこと ができるっていうのがインジェクション SQLインジェクションとか あとは もう一個が これも用語は覚えなくて いいんですけど クロスサイトスクリプティング XSSかなっていうのもあったりして こっちはデータベースではなくて ウェブページのところにプログラム JavaScriptっていうプログラムがあるん ですけど その命令を書かせること で同じようにデータを持っていった りとか データを持っていったり 何か意図しないページに誘導したり っていうことができたりっていう ところもあったりして 要は誰でも 入力できるような入力欄があった ときに そこに対して悪意のある 人が悪意のある命令を書くと ちゃんと 対策をしてないとそういうセキュリティ 的に危ないよっていう そういうことが できちゃうっていうのが以前から というか これは昔から開発の現場 であるという話になっておりました なので そういうツールとかサイト を作る人は そういう命令みたいな ものが書かれていたとしても それを 絶対に命令としては処理しないで 必ずこれは文字ですよっていう ふうに何かしら意味をちゃんと 置き換えてから処理するっていうことが 重要になってくるというような ことがもともとあったというのが これまでの開発の話になっていて それに対してというか それに続いて 今 このAIの世界で出てくるのが 今度 プロンプトインジェクション というものが出てきております これも同じようにプロンプト つまり AIへの指示文に対して何か悪意のある 命令を忍ばせるというようなこと によって AIを騙して これ また 不正な動きをさせるというような ことも今のところ現実的にできて しまうというものがあります 普段 チャットGPTとかクロードとか でやりとりしていく分には恐らく 問題はないんですけれども そこに 自分じゃない誰かが書いた何か の命令を使うというときにもしかしたら 公式のサイトとかではないにしても 例えば特定のゲームを作るような 何か文字を打つと簡単にツール が作れるよみたいなサイトがあった ときに 見た目上はツールを作る サイトなんですけれども 個人情報 とかそこで書くと 実はAIを使って 全然別のところに情報が送られた りとか そういうのがあったりとか 具体的に僕が以前作って これ危ない なって思ったのが ボットを1個 作って ディスコードボットですね AIで動くディスコードボットを 作ったんですけど それは何か自由に 質問すると それに対して返答 してくれるっていうボットになって いて ディスコードで結構危ない とされてるのが リンクを投稿させる とか あとは不特定多数に通知を 飛ばすっていうことがあって 一度 作ったボットに対して みんな エブリワンに呼びかけてよみたいな ことを言ったら 確かエブリワン できちゃったみたいなのがあるんですね っていうのがあって なのでそういう ふうにいたずらで今いる人に全て に通知が遅れちゃうみたいな そういう 事例もあったりするので ちょっと すいません あんまり明確なという か分かりやすい事例がなかなか 出せずに申し訳ないんですけれども そういうですね これまた第三者 が何か命令 指示を出せる環境で AIを動かすときに 自分がそのツール を作った側でも 誰かが作ったツール を使う側でもそうなんですけれども 悪意ある指示が入っていたときに 大丈夫かっていうのは一度考えた ほうがいいかなと思います さっき のディスコードの例で言うと 結構 これ処理が難しくて 事前にルール としてエブリワンは絶対やらないで くださいとか そういうことを言った としても確実に防げるというわけ じゃないので そういうときには 返答を作ったときに そこの文字列 をチェックして 本当にエブリワン っていうのが入ってないかなみたいな そういうのを見たりとか 結構 誰でも自由に使えるようなツール を作るときには こういう何でも どんな命令でも入りうるということ があるので このインジェクション 攻撃ですね 特に今で言うと多分 AIのプロンプトインジェクション というものが影響するかなという のがあるので 全員が全員を持って 使うんじゃないよっていうことは 大前提として考えた上で作って みるといいのかなと思います ただ これに関してはあまり明確に こうやったら絶対に直せます 絶対に回避できますっていうところ が さっき言ったSQLインジェクション とかクロスサイトスクリプティング とかで言うと ある程度 この文字 をただの文字列に一回変換して からみたいなエスケープ処理みたいな のをやるっていうことで解決は できるんですけれども AIに関して で言うと自由度が本当に広い分 事前のルールで縛っておくっていう のが一つと あとはAIが回答を生成 した後にももう一回二段チェック みたいなのを入れるっていう必要 もあるのかなっていうので この辺り はそういったツールを作る場面 は少ないかもしれないですけど そういう命令が間に入ったらどう なるっていうのを事前に想像してから 作るだけでもリスクとしては下がる と思うので 一応そういう手法がある ということは今回覚えておいて もらえればいいかなと思ってお話 をさせていただきました この辺も僕もそこまでめっちゃ 詳しいというわけではなくて 何回 かヒヤッとしたことがあったので 知識としてインジェクション攻撃 というのがあって 特に第三者 自分 以外の人が自由に何か文章を記述 できるっていうときに起こりうる という話になっていて 何かツール とか作る側 使う側 どっちもです けれども 仮にこの悪意のある人 が仕込んでいた場合に大丈夫か どうかということを一度軽く想像 してから作ったりとかチェック するのがおすすめだよというそんな 話になります ということで今回は以上になります 本日もお聞きくださいまして ありがとうございました
